{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07190003-7cf0-4bde-a60c-7da33b6154ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaggu/anaconda3/envs/torch_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./fine_tuned_t5_spider_sql_generator on: cuda\n",
      "\n",
      "Loading Spider dev (validation) set for prediction...\n",
      "Loaded 1034 examples for prediction.\n",
      "\n",
      "Generating SQL predictions for 1034 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1034/1034 [02:46<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions.sql'.\n",
      "\n",
      "Proceed to Step 2: Set up and run the official Spider evaluation script.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate_spider.py - Script to generate predictions for the dev set\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset # Used for loading dev.json cleanly\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm # For progress bar\n",
    "\n",
    "# --- Configuration ---\n",
    "# This path should point to where main_spider.py saved your trained model\n",
    "MODEL_PATH = \"./fine_tuned_t5_spider_sql_generator\"\n",
    "TOKENIZER = T5Tokenizer.from_pretrained(MODEL_PATH)\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# --- IMPORTANT: DATASET_DIR needs to be the same as in main_spider.py ---\n",
    "DATASET_DIR = \"/home/jaggu/Deep_L/spider_dataset_extracted/spider_data\"\n",
    "\n",
    "# Verify paths\n",
    "if not os.path.isdir(DATASET_DIR):\n",
    "    raise FileNotFoundError(f\"DATASET_DIR '{DATASET_DIR}' does not exist. Please check your path.\")\n",
    "if not os.path.exists(os.path.join(DATASET_DIR, \"dev.json\")):\n",
    "    raise FileNotFoundError(f\"dev.json not found in '{DATASET_DIR}'. Ensure Spider files are extracted correctly.\")\n",
    "if not os.path.exists(os.path.join(DATASET_DIR, \"tables.json\")):\n",
    "    raise FileNotFoundError(f\"tables.json not found in '{DATASET_DIR}'. Ensure Spider files are extracted correctly.\")\n",
    "\n",
    "\n",
    "# Load the tables.json for schema lookup\n",
    "tables_file_path = os.path.join(DATASET_DIR, 'tables.json')\n",
    "with open(tables_file_path, 'r', encoding='utf-8') as f:\n",
    "    db_schemas = {db['db_id']: db for db in json.load(f)}\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL.to(device)\n",
    "MODEL.eval() # Set model to evaluation mode\n",
    "\n",
    "print(f\"Model loaded from {MODEL_PATH} on: {device}\")\n",
    "\n",
    "\n",
    "# --- Schema Representation Function (MUST be identical to the one used during training) ---\n",
    "def get_schema_representation(db_id, db_schemas_dict):\n",
    "    \"\"\"\n",
    "    Generates a textual representation of the database schema for a given db_id.\n",
    "    Includes table names, column names, and their types.\n",
    "    \"\"\"\n",
    "    schema = db_schemas_dict[db_id]\n",
    "    schema_parts = []\n",
    "    \n",
    "    for table_idx, table_name_original in enumerate(schema['table_names_original']):\n",
    "        schema_parts.append(f\"table {table_idx}: {table_name_original}\")\n",
    "        \n",
    "        table_cols = []\n",
    "        for col_idx, (col_table_idx, col_name_original) in enumerate(schema['column_names_original']):\n",
    "            if col_table_idx == table_idx:\n",
    "                col_type = schema['column_types'][col_idx]\n",
    "                table_cols.append(f\"column {col_idx}: {col_name_original} ({col_type})\")\n",
    "        \n",
    "        if table_cols:\n",
    "            schema_parts.append(\"  \" + \"; \".join(table_cols))\n",
    "            \n",
    "    return \" | \".join(schema_parts)\n",
    "\n",
    "\n",
    "# --- SQL Query Generation Function ---\n",
    "def generate_sql_query(nl_question, db_id):\n",
    "    \"\"\"\n",
    "    Generates an SQL query from a natural language question and a database ID.\n",
    "    \"\"\"\n",
    "    schema_text = get_schema_representation(db_id, db_schemas)\n",
    "    input_text = f\"generate sql: {schema_text} | question: {nl_question}\"\n",
    "    \n",
    "    inputs = TOKENIZER(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        outputs = MODEL.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=512,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "\n",
    "    generated_sql = TOKENIZER.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_sql\n",
    "\n",
    "# --- Load the Spider Dev Set ---\n",
    "# Use the same normalization function as in main_spider.py for consistency\n",
    "def load_and_normalize_spider_split(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    questions = []\n",
    "    queries = []\n",
    "    db_ids = []\n",
    "    for item in data:\n",
    "        sql_query = item['query']\n",
    "        if isinstance(sql_query, list):\n",
    "            sql_query = sql_query[0] if sql_query else \"\"\n",
    "        if 'question' in item and 'db_id' in item and sql_query is not None:\n",
    "            questions.append(item['question'])\n",
    "            queries.append(sql_query)\n",
    "            db_ids.append(item['db_id'])\n",
    "    return Dataset.from_dict({'question': questions, 'query': queries, 'db_id': db_ids})\n",
    "\n",
    "print(\"\\nLoading Spider dev (validation) set for prediction...\")\n",
    "dev_dataset = load_and_normalize_spider_split(os.path.join(DATASET_DIR, 'dev.json'))\n",
    "print(f\"Loaded {len(dev_dataset)} examples for prediction.\")\n",
    "\n",
    "# --- Generate Predictions and Save to File ---\n",
    "output_predictions_file = \"predictions.sql\" # This will be created in your current working directory\n",
    "\n",
    "print(f\"\\nGenerating SQL predictions for {len(dev_dataset)} examples...\")\n",
    "generated_sqls = []\n",
    "for i, example in tqdm(enumerate(dev_dataset), total=len(dev_dataset)):\n",
    "    question = example['question']\n",
    "    db_id = example['db_id']\n",
    "    \n",
    "    pred_sql = generate_sql_query(question, db_id)\n",
    "    generated_sqls.append(pred_sql)\n",
    "\n",
    "# Write predictions to a file, one query per line\n",
    "with open(output_predictions_file, 'w', encoding='utf-8') as f:\n",
    "    for sql in generated_sqls:\n",
    "        f.write(sql.strip() + '\\n')\n",
    "\n",
    "print(f\"Predictions saved to '{output_predictions_file}'.\")\n",
    "print(\"\\nProceed to Step 2: Set up and run the official Spider evaluation script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e126ccd-f578-4dec-86f2-0ed2ad9c5bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
